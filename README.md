# ğŸ§  Production-ready RAG Chatbot

Production-ready RAG Chatbot is a fully containerized, orchestrated application designed to bring **Retrieval-Augmented Generation (RAG)** into production environments with ease.

---

## ğŸ“½ Demo

https://github.com/user-attachments/assets/3044c441-0a5b-4dd8-a112-5cbe13b84365

---

## ğŸ“ Project Structure

```text
prod-rag-chatbot/
â”œâ”€â”€ backend/                        # Backend logic for RAG pipeline
â”‚   â”œâ”€â”€ main.py                     # FastAPI endpoints for PDF upload, chat, session cleanup
â”‚   â”œâ”€â”€ embedding_utils.py          # Handles embedding documents & uploading to Qdrant
â”‚   â”œâ”€â”€ pdf_utils.py                # Extracts and chunks text from PDFs
â”‚   â”œâ”€â”€ qa_utils.py                 # Builds QA chain using HuggingFace LLM + Qdrant retriever
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .env                        # Backend config (API keys, host info)
â”‚   â””â”€â”€ pyproject.toml              # Poetry dependencies
â”‚
â”œâ”€â”€ frontend/                       # Streamlit UI for uploading, chatting, and ending session
â”‚   â”œâ”€â”€ app.py                      # Main Streamlit interface (chat + PDF uploader)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml              # Poetry dependencies
â”‚
â”œâ”€â”€ qdrant_data/                    # Persistent Qdrant volume for storing vectors
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml              # Orchestrates frontend, backend, and Qdrant containers
â””â”€â”€ .venv/                          # Python virtual environment
```

---

### ğŸ§± Microservices Architecture Overview
![Architecture](assets/Architecture.drawio.svg)

### ğŸ”„ Flow Diagram
![Flow](assets/Flow_Diagram.drawio.svg)

---

## ğŸ§° Tech Stack

- **FastAPI** â€” Async backend for document ingestion and querying
- **Streamlit** â€” Lightweight UI for interacting with the bot
- **Qdrant** â€” Vector store for efficient retrieval
- **Hugging Face (Mistral-7B)** â€” LLM used for final answer generation
- **LangChain** â€” Manages pipelines for embedding, retrieval, and QA
- **SentenceTransformers** â€” Used for embedding via `all-MiniLM-L6-v2`
- **PyMuPDF** â€” PDF parsing
- **Docker + Compose** â€” Containerized setup

---

## âš™ï¸ Setup & Installation

### 1. Clone the Repo

```bash
git clone https://github.com/shivamsingh-ml/production-rag-chatbot.git
cd production-rag-chatbot
```

### 2. Configure Environment Variables

Create a `.env` file in `backend/`:

```env
HUGGINGFACEHUB_API_TOKEN=your_huggingface_key
QDRANT_HOST=qdrant
QDRANT_PORT=6333
```

### 3. Start Services with Docker Compose

```bash
docker-compose up --build
```

This will launch:
- FastAPI backend at `http://localhost:8000`
- Streamlit frontend at `http://localhost:8501`
- Qdrant vector database at `http://localhost:6333`

---

## ğŸš€ Usage (Web Interface)

Visit the frontend at [`http://localhost:8501`](http://localhost:8501)

1. **Upload PDF** â€” Accepts a single PDF file.
2. **Start Session** â€” Embeds the document and stores it in Qdrant.
3. **Chat** â€” Type natural language questions to interact with the document.
4. **End Session** â€” Deletes the sessionâ€™s Qdrant collection.

Each session is isolated via a unique `session_id`. Chat state is preserved in the app until cleared.

---

## ğŸ§ª API Endpoints

- `POST /upload-pdf/` â€” Upload and process PDF
- `POST /chat` â€” Ask a question with `session_id`
- `POST /delete-collection/` â€” Delete session vector store

Example request:

```bash
curl -X POST http://localhost:8000/chat      -H "Content-Type: application/json"      -d '{"query": "Summarize the document", "session_id": "abc-123"}'
```

---

## ğŸ“¦ Poetry (Backend & Frontend)

Both services use Poetry for dependency management.

To use locally (example for backend):

```bash
cd backend
poetry install
poetry run uvicorn main:app --reload
```

---


---

## ğŸ³ Docker Instructions

You can run the entire RAG Chatbot stack using Docker Compose. This setup includes:

- `backend` â€” FastAPI app for PDF upload, vector DB interaction, and QA
- `frontend` â€” Streamlit UI to interact with the bot
- `qdrant` â€” Vector database

### ğŸ› ï¸ Build & Run (Recommended)

```bash
docker-compose up --build
```

- Frontend will be available at: [http://localhost:8501](http://localhost:8501)
- Backend API will run at: [http://localhost:8000](http://localhost:8000)
- Qdrant vector DB UI (if needed): [http://localhost:6333](http://localhost:6333)

### ğŸ§¼ Tear Down

```bash
docker-compose down
```

To remove named volumes and containers completely:

```bash
docker-compose down -v
```

### ğŸ”„ Rebuild after Code Changes

```bash
docker-compose build
```


## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first.

---

